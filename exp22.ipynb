{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"i\",\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"to\",\"from\",\"up\",\"down\",\"in\",\"on\",\"off\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"other\",\"some\",\"such\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "tokenize = spacy.load('en_core_web_sm')\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_pos = \"/home/cvh255/nlp_hw1/aclImdb/train/pos/\"\n",
    "path_train_neg = \"/home/cvh255/nlp_hw1/aclImdb/train/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_files = os.listdir(path_train_pos)\n",
    "for f in range(len(train_pos_files)):\n",
    "    train_pos_files[f] = path_train_pos + train_pos_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_files = os.listdir(path_train_neg)\n",
    "for f in range(len(train_neg_files)):\n",
    "    train_neg_files[f] = path_train_neg + train_neg_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_labels = [1]*len(train_pos_files)\n",
    "train_neg_labels = [0]*len(train_neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"file_names\",\"labels\"])\n",
    "df[\"file_names\"] = train_pos_files+train_neg_files\n",
    "df[\"labels\"] = train_pos_labels+train_neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9258_10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3_10.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9597_10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3347_7.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/2160_8.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_names  labels\n",
       "0  /home/cvh255/nlp_hw1/aclImdb/train/pos/9258_10...       1\n",
       "1    /home/cvh255/nlp_hw1/aclImdb/train/pos/3_10.txt       1\n",
       "2  /home/cvh255/nlp_hw1/aclImdb/train/pos/9597_10...       1\n",
       "3  /home/cvh255/nlp_hw1/aclImdb/train/pos/3347_7.txt       1\n",
       "4  /home/cvh255/nlp_hw1/aclImdb/train/pos/2160_8.txt       1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss.split(df[\"file_names\"], df[\"labels\"]):\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 2), (5000, 2))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    all_txt = []\n",
    "    for i,j in df.iterrows():\n",
    "        f = open(j[\"file_names\"])\n",
    "        txt = f.read()\n",
    "        all_txt.append(txt)\n",
    "#         print(j)\n",
    "    df[\"content\"] = all_txt\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df = get_data(train_df)\n",
    "val_df = get_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "def tokenize1(phrase):\n",
    "    tokens = tokenize(phrase)\n",
    "    return [token.text.lower() for token in tokens if (token.text not in punctuations and token.text not in stop_words)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = list(ngrams(tokenize1(\"I am going mad! you are nuts and mad again\"),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'going', 'mad', 'nuts'), ('going', 'mad', 'nuts', 'mad')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i going mad', 'going mad nuts']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(a) for a in bg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset1(dataset,n_gram):\n",
    "    token_dataset = []\n",
    "    all_tokens = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenize1(sample)\n",
    "        bg = list(nltk.bigrams(tokens))\n",
    "        tg = list(nltk.trigrams(tokens))\n",
    "        fg = list(ngrams(tokens,4))\n",
    "        bg_t = [' '.join(a) for a in bg]\n",
    "        tg_t = [' '.join(a) for a in tg]\n",
    "        fg_t = [' '.join(a) for a in fg]\n",
    "        tokens = tokens + bg_t + tg_t + fg_t\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens+=tokens\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "print (\"Tokenizing val data\")\n",
    "val_df[\"tokenized1\"], _ = tokenize_dataset1(val_df[\"content\"],1)\n",
    "# pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# train set tokens\n",
    "print (\"Tokenizing train data\")\n",
    "train_df[\"tokenized1\"], all_train_tokens = tokenize_dataset1(train_df[\"content\"],1)\n",
    "# pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenized1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>After seeing this film I feel like I know just...</td>\n",
       "      <td>[after, seeing, film, i, feel, like, i, know, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>My son was 7 years old when he saw this movie,...</td>\n",
       "      <td>[my, son, 7, years, old, saw, movie, russian, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Remember the early days of Pay Per View? I do,...</td>\n",
       "      <td>[remember, early, days, pay, per, view, i, alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...</td>\n",
       "      <td>1</td>\n",
       "      <td>And that's how the greatest comedy of TV start...</td>\n",
       "      <td>[and, 's, greatest, comedy, tv, started, it, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily Mars, a smalltown girl living in Indiana,...</td>\n",
       "      <td>[lily, mars, smalltown, girl, living, indiana,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_names  labels  \\\n",
       "8283   /home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt       1   \n",
       "10937  /home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...       1   \n",
       "9347   /home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt       1   \n",
       "5430   /home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...       1   \n",
       "4072   /home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt       1   \n",
       "\n",
       "                                                 content  \\\n",
       "8283   After seeing this film I feel like I know just...   \n",
       "10937  My son was 7 years old when he saw this movie,...   \n",
       "9347   Remember the early days of Pay Per View? I do,...   \n",
       "5430   And that's how the greatest comedy of TV start...   \n",
       "4072   Lily Mars, a smalltown girl living in Indiana,...   \n",
       "\n",
       "                                              tokenized1  \n",
       "8283   [after, seeing, film, i, feel, like, i, know, ...  \n",
       "10937  [my, son, 7, years, old, saw, movie, russian, ...  \n",
       "9347   [remember, early, days, pay, per, view, i, alm...  \n",
       "5430   [and, 's, greatest, comedy, tv, started, it, 1...  \n",
       "4072   [lily, mars, smalltown, girl, living, indiana,...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df_tok5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(\"val_df_tok5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(all_train_tokens,open(\"all_tokens5\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df_tok1.csv\")\n",
    "val_df = pd.read_csv(\"val_df_tok1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "all_train_tokens = pickle.load(open(\"all_tokens1\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 33936 ; token really it 's\n",
      "Token really it 's; token id 33936\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_df['token_idized'] = token2index_dataset(train_df['tokenized1'])\n",
    "val_df['token_idized'] = token2index_dataset(val_df['tokenized1'])\n",
    "# test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenized1</th>\n",
       "      <th>token_idized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>After seeing this film I feel like I know just...</td>\n",
       "      <td>[after, seeing, film, i, feel, like, i, know, ...</td>\n",
       "      <td>[398, 253, 6, 2, 164, 11, 2, 60, 52, 154, 3834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>My son was 7 years old when he saw this movie,...</td>\n",
       "      <td>[my, son, 7, years, old, saw, movie, russian, ...</td>\n",
       "      <td>[303, 407, 1309, 86, 83, 140, 5, 1960, 7343, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Remember the early days of Pay Per View? I do,...</td>\n",
       "      <td>[remember, early, days, pay, per, view, i, alm...</td>\n",
       "      <td>[320, 334, 456, 997, 4083, 642, 2, 147, 320, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...</td>\n",
       "      <td>1</td>\n",
       "      <td>And that's how the greatest comedy of TV start...</td>\n",
       "      <td>[and, 's, greatest, comedy, tv, started, it, 1...</td>\n",
       "      <td>[57, 3, 827, 143, 173, 613, 12, 2463, 86, 170,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily Mars, a smalltown girl living in Indiana,...</td>\n",
       "      <td>[lily, mars, smalltown, girl, living, indiana,...</td>\n",
       "      <td>[4337, 6205, 1, 168, 555, 9991, 1467, 160, 127...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_names  labels  \\\n",
       "8283   /home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt       1   \n",
       "10937  /home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...       1   \n",
       "9347   /home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt       1   \n",
       "5430   /home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...       1   \n",
       "4072   /home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt       1   \n",
       "\n",
       "                                                 content  \\\n",
       "8283   After seeing this film I feel like I know just...   \n",
       "10937  My son was 7 years old when he saw this movie,...   \n",
       "9347   Remember the early days of Pay Per View? I do,...   \n",
       "5430   And that's how the greatest comedy of TV start...   \n",
       "4072   Lily Mars, a smalltown girl living in Indiana,...   \n",
       "\n",
       "                                              tokenized1  \\\n",
       "8283   [after, seeing, film, i, feel, like, i, know, ...   \n",
       "10937  [my, son, 7, years, old, saw, movie, russian, ...   \n",
       "9347   [remember, early, days, pay, per, view, i, alm...   \n",
       "5430   [and, 's, greatest, comedy, tv, started, it, 1...   \n",
       "4072   [lily, mars, smalltown, girl, living, indiana,...   \n",
       "\n",
       "                                            token_idized  \n",
       "8283   [398, 253, 6, 2, 164, 11, 2, 60, 52, 154, 3834...  \n",
       "10937  [303, 407, 1309, 86, 83, 140, 5, 1960, 7343, 2...  \n",
       "9347   [320, 334, 456, 997, 4083, 642, 2, 147, 320, 5...  \n",
       "5430   [57, 3, 827, 143, 173, 613, 12, 2463, 86, 170,...  \n",
       "4072   [4337, 6205, 1, 168, 555, 9991, 1467, 160, 127...  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.iloc[2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data_frame = csv_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx,self.data_frame[\"token_idized\"][idx])\n",
    "        token_idx = self.data_frame.iloc[idx][\"token_idized\"]\n",
    "        label = self.data_frame.iloc[idx]['labels']\n",
    "#         print(token_idx)\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_fun(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "#     print(batch[0])\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    for datum in batch:\n",
    "        if datum[1]>MAX_SENTENCE_LENGTH:\n",
    "            padded_vec = np.array(datum[0][:MAX_SENTENCE_LENGTH])\n",
    "        else:\n",
    "            padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH - datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "#         print(padded_vec.shape)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(length_list)), torch.from_numpy(np.array(label_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "train_dataset = IMDBDataset(train_df)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun,\n",
    "                                           shuffle = True)\n",
    "\n",
    "val_dataset = IMDBDataset(val_df)\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_dataset, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun,\n",
    "                                           shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# d = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super(BagOfWords, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx = 0)\n",
    "#         self.linear = nn.Linear(emb_dim,20)\n",
    "        self.linear = nn.Linear(emb_dim,2)\n",
    "#         self.linear2 = nn.Linear(100,300)\n",
    "#         self.linear3 = nn.Linear(300,2)\n",
    "#         self.dp = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "#         out = F.relu(self.linear(out.float()))\n",
    "#         out = F.relu(self.linear2(out.float()))\n",
    "#         out = self.linear3(out.float())\n",
    "#         print(out.size())\n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = [train_loader,val_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,criterion, optimizer, name, num_epochs):\n",
    "    best_loss = np.inf\n",
    "    best_acc = 0\n",
    "    loss_hist = {'train':[],'validate':[]}\n",
    "    for i in range(num_epochs):\n",
    "        for enu,phase in enumerate(['train', 'validate']):\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "            for (data, lengths, labels) in dataloaders[enu]:\n",
    "                data_batch, length_batch, label_batch = data.cuda(), lengths.cuda(), labels.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data_batch, length_batch)\n",
    "                loss = criterion(outputs, label_batch)\n",
    "                if phase=='train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                N = labels.size(0)\n",
    "                \n",
    "                outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "                predicted = outputs.max(1, keepdim=True)[1]\n",
    "#                 print(type(predicted))\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels.view_as(predicted).cuda()).sum().item()\n",
    "                running_loss += loss.data[0] * N\n",
    "                running_total += N\n",
    "            epoch_loss = running_loss/running_total\n",
    "            loss_hist[phase].append(epoch_loss.item())\n",
    "            accuracy = 100 * correct / total\n",
    "            print('Epoch: {}, Phase: {}, epoch loss: {:.4f}, accuracy: {:.4f}'\\\n",
    "                      .format(i,phase,epoch_loss, accuracy))\n",
    "        if phase == 'validate' and epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_acc = accuracy\n",
    "            torch.save(model,name)\n",
    "    print('Best val dice loss: {:4f}, Best Accuracy: {:4f}'.format(best_loss,best_acc))\n",
    "    return model, loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Phase: train, epoch loss: 0.4539, accuracy: 80.2500\n",
      "Epoch: 0, Phase: validate, epoch loss: 0.2701, accuracy: 89.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BagOfWords. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Phase: train, epoch loss: 0.1324, accuracy: 96.6100\n",
      "Epoch: 1, Phase: validate, epoch loss: 0.2549, accuracy: 90.3400\n",
      "Epoch: 2, Phase: train, epoch loss: 0.0372, accuracy: 99.5650\n",
      "Epoch: 2, Phase: validate, epoch loss: 0.2824, accuracy: 89.9200\n",
      "Epoch: 3, Phase: train, epoch loss: 0.0124, accuracy: 99.9400\n",
      "Epoch: 3, Phase: validate, epoch loss: 0.2937, accuracy: 90.5400\n",
      "Epoch: 4, Phase: train, epoch loss: 0.0057, accuracy: 99.9900\n",
      "Epoch: 4, Phase: validate, epoch loss: 0.3133, accuracy: 90.3400\n",
      "Epoch: 5, Phase: train, epoch loss: 0.0033, accuracy: 100.0000\n",
      "Epoch: 5, Phase: validate, epoch loss: 0.3262, accuracy: 90.4200\n",
      "Epoch: 6, Phase: train, epoch loss: 0.0022, accuracy: 100.0000\n",
      "Epoch: 6, Phase: validate, epoch loss: 0.3386, accuracy: 90.4400\n",
      "Epoch: 7, Phase: train, epoch loss: 0.0015, accuracy: 100.0000\n",
      "Epoch: 7, Phase: validate, epoch loss: 0.3495, accuracy: 90.4400\n",
      "Epoch: 8, Phase: train, epoch loss: 0.0011, accuracy: 100.0000\n",
      "Epoch: 8, Phase: validate, epoch loss: 0.3595, accuracy: 90.4400\n",
      "Epoch: 9, Phase: train, epoch loss: 0.0009, accuracy: 100.0000\n",
      "Epoch: 9, Phase: validate, epoch loss: 0.3685, accuracy: 90.4400\n",
      "Best val dice loss: 0.254942, Best Accuracy: 90.340000\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 300\n",
    "model = BagOfWords(len(id2token), emb_dim).cuda()\n",
    "# model = nn.DataParallel(model)\n",
    "learning_rate = 0.01\n",
    "# num_epochs = 100\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "# optimizer = torch.optim.SGD(model)\n",
    "\n",
    "\n",
    "m_save, loss_hists = training(model,criterion,optimizer,\"model25_tokenize2\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2af607949860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hists['train'],label=\"train loss\")\n",
    "plt.plot(loss_hists['validate'],label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(loss_hists,open(\"loss_hist25_t2\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset_test(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data_frame = csv_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(self.data_frame.iloc[idx].index)\n",
    "        file_name = self.data_frame.iloc[idx][\"file_names\"]\n",
    "        token_idx = self.data_frame.iloc[idx][\"token_idized\"]\n",
    "        label = self.data_frame.iloc[idx]['labels']\n",
    "        return [token_idx, len(token_idx), label,file_name]\n",
    "\n",
    "\n",
    "def pad_fun_test(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    file_names = []\n",
    "#     print(batch[0])\n",
    "    for datum in batch:\n",
    "        \n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "        file_names.append(datum[3])\n",
    "    for datum in batch:\n",
    "        if datum[1]>MAX_SENTENCE_LENGTH:\n",
    "            padded_vec = np.array(datum[0][:MAX_SENTENCE_LENGTH])\n",
    "        else:\n",
    "            padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH - datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "#         print(padded_vec.shape)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(length_list)), torch.from_numpy(np.array(label_list)),np.array(file_names)]\n",
    "\n",
    "val_dataset_test = IMDBDataset_test(val_df)\n",
    "val_loader_test = torch.utils.data.DataLoader(dataset = val_dataset_test, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun_test,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_saved = torch.load(\"model25_tokenize2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, lengths, labels, file_n = next(iter(val_loader_test))\n",
    "data_batch, length_batch, label_batch = data.cuda(), lengths.cuda(), labels.cuda()\n",
    "outputs = mod_saved(data_batch, length_batch)\n",
    "outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "predicted = outputs.max(1, keepdim=True)[1]\n",
    "mask =(predicted.squeeze(1).eq(label_batch)).cpu().data.numpy()==0\n",
    "fns = file_n[mask]\n",
    "actual_out = labels.data.numpy()[mask]\n",
    "pred_false = predicted.cpu().data.numpy()[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/106_2.txt\n",
      "1st watched 8/3/2003 - 2 out of 10(Dir-Brad Sykes): Mindless 3-D movie about flesh-eating zombies in a 3 story within a movie chronicle. And yes, we get to see zombies eating human flesh parts in 3D!! Wow, not!! That has been done time and time again in 2D in a zombie movie but what usually makes a zombie movie better is the underlying story not the actual flesh-eating. That's what made the original zombie classics good. The flesh-eating was just thrown in as an extra. We're actually bored throughout most of this 3-part chronicle because of the lame(twilight-zone like) easily understood and slow-pacingly revealed finale's. The last story is actually the story the movie started with(having a reporter investigating a so-called ghost town) and of course we get to see flesh eating zombie's in that one as well. Well, I think I've said enough. Watch the classics, not this 3D bore-feast.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/7942_1.txt\n",
      "Really. Does any week go by that Oprah doesn't remind us that she was abused as child?<br /><br />She makes herself the focus of every interview.<br /><br />Oprah cannot resist commenting on the answer to every question she asks. She often interrupts guests before an answer is finished to interject her own aside or anecdote. Directors are obviously instructed to focus on her closeup reaction rather than guest's faces because that's what counts - what Oprah feels, what Oprah says.<br /><br />Oprah, Oprah, Oprah. It's always all about Oprah.<br /><br />Oprah says - Feel sorry for me, I was so poor. Feel the pain of my battle with my weight. Feel my hurt when I'm turned away from a fancy store after they've already closed. Feel good for buying my magazines and books. Feel good for my success. Feel good when you give to my charity to make me look good. Feel good for making me rich beyond belief.<br /><br />My interpretation of her point of view: YOU VIEWERS ARE ALL DEEPLY FLAWED AND YOU NEED MY DAILY ADVICE. I have all the answers for your life though I have nothing in common with you plebes. I have never been married nor do I want to be. I have never had to raise a family - but I know all about it. I have little respect for men or marriage. I clearly prefer people like me over others - witness \"Legends Ball 2006\". Gayle is my best friend but we are not gay.<br /><br />As of 7/31/2006, the heading on her website actually reads : \"Oprah.com is your leading source for information about love, life, self, relationships, food, home, spirit and health.\" How presumptive and obnoxious is that ? <br /><br />In June 2006, she crashed two private wedding receptions in Oklahoma to gather footage for her September 2006 shows. She keeps promising to quit TV but her yapfest drags on with no end in sight.<br /><br />Contrary to what she thinks, Oprah is neither a queen nor a goddess nor on a personal mission from God. She's just one very lucky, overweight, black woman who copied Phil Donahue's style and called it her own. She happened to be in the right place at the right time and knew exactly how to suck up to the right demographic. <br /><br />Oprah is the P.T. Barnum of this age and it amazes me that people cannot see through her facade. <br /><br />So ladies and gentlemen, boys and girls and you too Oprah if you can fit that inflated ego through the door - This way now to the great egress ...\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/pos/11603_10.txt\n",
      "The first time i saw it i got half of it but i watched and i knew later on it was about a salem witch trials. They focused on the Sara Good's family. SHE is famous for cursing a priest which came true. In the film it depicts her daughter dorcas and her husband the spirit of Ann Putnam Sara's husband comes to the future hunts this girl to redeem her soul. which does happen at the end of the movie. Dorcas is depict as witch at 5years old who is burned at the stake. Which never happen Ann putnam saves her from the flames. the girl is safe she goes to Ann putnam's grave to to see that is not empty but it is at first because she accuse her of witchcraft, and lets her burn to death. Now that ann putnam saves her her spirit is redeemed, and she is not a outcast to society for the salem witch trials.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/636_4.txt\n",
      "A couple of farmers struggle in life in a small village in China. Wang Lung (Paul Muni) buys O-Lan, his future wife, who becomes his slave (Luis Rainer). American stars appear in the leading roles, talking with fake accents and emphasizing old stereotypes and patriarchal ideology. A good wife, many children and land are the best things for men to have. They are seen as property and investment. Because it is a big budget movie, in which many extras cooperate, big sets are built and special effects take place, the movie makers could not take the risk of hiring less popular actors. Luise Rainer won an Academy Award for this performance, which is definitely the worst in the movie. Her immutable face builds a barrier between her and the audience. O-Lan is supposed to be the heart of the family and the best character to sympathize with. On the other hand Paul Muni gives a better performance, showing his talent ones again. Another problem with the movie is the ending. It seems like Franklin did not know when to end the picture. This film could be dangerous if it is taken as a truly example of Chinese culture and traditions.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/7273_4.txt\n",
      "This early role for Barbara Shelley(in fact,her first in Britain after working in Italy),was made when she was 24 years old,and it's certainly safe to say that she made a stunning debut in 1957's \"Cat Girl.\" While blondes and brunettes get most of the attention(I'll always cherish Yutte Stensgaard),the lovely auburn-haired actress with the deep voice always exuded intelligence as well as vulnerability(one such example being 1960's \"Village of the Damned,\" in which her screen time was much less than her character's husband,George Sanders).She is the sole reason for seeing this drab update of \"Cat People,\" and is seen to great advantage throughout(it's difficult to say if her beauty found an even better showcase).Her character apparently sleeps in the nude,and we are exposed to her luscious bare back when she is awakened(also exposed 8 years later in 1965's \"Rasputin-The Mad Monk\").The ravishing gown she wears during most of the film is a stunning strapless wonder(I don't see what held that dress up,but I'd sure like to).All in all,proof positive that Barbara Shelley,in a poorly written role that would defeat most actresses,rises above her material and makes the film consistently watchable,a real test of star power,which she would find soon enough at Hammer's studios in Bray,for the duration of the 1960's.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/10958_4.txt\n",
      "Having watched this after receiving the DVD for Christmas 2005, I came here to pan it -- but after reading the other comments, I haven't the heart. Clearly this is a film that has worked very well for children of a certain age. Well, let me not be a complete Grinch; it might still work for some children -- if they are not too media-saturated and have not become visually over-sophisticated, e.g. from watching all of LOTR and Harry Potter. But if you are an adult, stay miles away; you will not enjoy it.<br /><br />The good bits: Barbara Kellerman as the Witch, especially in her early scenes with Edmund, creates just the right blend of charismatic evil and restrained madness. (At the Stone Table she goes a bit over the top.) Michael Aldridge in the minor role of the Professor and Jeffrey S. Perry as Mr. Tumnus also have the kind of polished, skillful acting we'd expect from the very best BBC dramas. And the Aslan costume works very well, amazingly well considering. They got the eyes just right.<br /><br />The bad bits: almost everything else, but two areas in particular. One, the casting. England is crammed with good actors and contains tens of thousands of attractive British school kids. How could they possibly have ended up with these four stiffs? They move like wooden soldiers and speak about as well. Peter has no gravitas or charisma (and is visibly shorter than his supposedly younger siblings); Edmund is just whiny; and Lucy... Sophie Wilcox as Lucy is so dramatically, visibly, drastically wrong for this part that I can't imagine how she got the job.<br /><br />Two, the animal costumes. Again, it appears that they worked for some kids. If the kids are still at a level where Big Bird and Elmo are exciting, believable characters, they might be entranced by this film. But to a viewer with the sophistication of, say, a 12-year-old who's seen Prisoner Of Azkaban? When Mister Beaver comes out from behind that tree, there will be hoots of cruel, derisive laughter. The costumes just do not work -- I could not, and I think any adult or modern teen could not, suspend disbelief when looking at Mister Beaver. The drawn animation later (gryphons, etc.) works better, is easier to take.<br /><br />So: ten stars for the very young and tender of soul; everyone else read, or re-read the book and watch the far better film that unrolls in your imagination.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/5013_1.txt\n",
      "I won't argue with anyone who pronounces this film execrable, as is January Jones's performance, but please check her out, if you haven't already, in the AMC TV series 'Mad Men,\" starting later this month. She's excellent, as is the entire cast. I'll charitably assume she took on the \"Taboo\" role strictly for the money, and, realizing what a putrid mess it was going to be, turned in a minimal acting job to avoid starvation. Don't know if that's the case, but I (now) know for sure that she can act.<br /><br />At first, watching \"Taboo,\" I was convinced her flat delivery was a shrewd choice that would later give rise to some significant revelation about her character or the plot. No such luck. Hard to believe the director didn't suggest to her at least once that not changing expression for 17 successive scenes could cause lockjaw.<br /><br />Ironically, her winning performance in \"Mad Men\" comes as a character who, at least in her early appearances, is very repressed, reserved, unsure of herself, and rather colorless, not unlike her \"Taboo\" role. But as the TV series progressed, she began to blossom into someone who questions her traditional early-60's whitebread Mom role. Can't wait to see where they take her character in the 2nd season.<br /><br />To sum up, avoid \"Taboo\" like leprosy, but definitely check out \"Mad Men.\"\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fns)):\n",
    "    print(\"predicted\",pred_false[i][0])\n",
    "    print(\"Actual\",actual_out[i])\n",
    "    print(val_df[val_df['file_names'] ==fns[i]][\"file_names\"].values[0])\n",
    "    f = open(val_df[val_df['file_names'] ==fns[i]][\"file_names\"].values[0])\n",
    "    print(f.read())\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
