{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "MAX_SENTENCE_LENGTH = 300\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"i\",\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"to\",\"from\",\"up\",\"down\",\"in\",\"on\",\"off\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"other\",\"some\",\"such\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "tokenize = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_pos = \"/home/cvh255/nlp_hw1/aclImdb/train/pos/\"\n",
    "path_train_neg = \"/home/cvh255/nlp_hw1/aclImdb/train/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_files = os.listdir(path_train_pos)\n",
    "for f in range(len(train_pos_files)):\n",
    "    train_pos_files[f] = path_train_pos + train_pos_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_files = os.listdir(path_train_neg)\n",
    "for f in range(len(train_neg_files)):\n",
    "    train_neg_files[f] = path_train_neg + train_neg_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_labels = [1]*len(train_pos_files)\n",
    "train_neg_labels = [0]*len(train_neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"file_names\",\"labels\"])\n",
    "df[\"file_names\"] = train_pos_files+train_neg_files\n",
    "df[\"labels\"] = train_pos_labels+train_neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9258_10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3_10.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9597_10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3347_7.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/2160_8.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_names  labels\n",
       "0  /home/cvh255/nlp_hw1/aclImdb/train/pos/9258_10...       1\n",
       "1    /home/cvh255/nlp_hw1/aclImdb/train/pos/3_10.txt       1\n",
       "2  /home/cvh255/nlp_hw1/aclImdb/train/pos/9597_10...       1\n",
       "3  /home/cvh255/nlp_hw1/aclImdb/train/pos/3347_7.txt       1\n",
       "4  /home/cvh255/nlp_hw1/aclImdb/train/pos/2160_8.txt       1"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss.split(df[\"file_names\"], df[\"labels\"]):\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 2), (5000, 2))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape,val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    all_txt = []\n",
    "    for i,j in df.iterrows():\n",
    "        f = open(j[\"file_names\"])\n",
    "        txt = f.read()\n",
    "        all_txt.append(txt)\n",
    "#         print(j)\n",
    "    df[\"content\"] = all_txt\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df = get_data(train_df)\n",
    "val_df = get_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "def tokenize1(phrase):\n",
    "    tokens = tokenize(phrase)\n",
    "    return [token.text.lower() for token in tokens if (token.text not in punctuations and token.text not in stop_words)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = list(nltk.bigrams(tokenize1(\"I am going mad! you are nuts\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'going'), ('going', 'mad'), ('mad', 'nuts')]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i going', 'going mad', 'mad nuts']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(a) for a in bg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset1(dataset,n_gram):\n",
    "    token_dataset = []\n",
    "    all_tokens = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenize1(sample)\n",
    "        bg = list(nltk.bigrams(tokens))\n",
    "        bg_t = [' '.join(a) for a in bg]\n",
    "        tokens = tokens + bg_t\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens+=tokens\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing val data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing train data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "print (\"Tokenizing val data\")\n",
    "val_df[\"tokenized1\"], _ = tokenize_dataset1(val_df[\"content\"],1)\n",
    "# pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# train set tokens\n",
    "print (\"Tokenizing train data\")\n",
    "train_df[\"tokenized1\"], all_train_tokens = tokenize_dataset1(train_df[\"content\"],1)\n",
    "# pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenized1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>After seeing this film I feel like I know just...</td>\n",
       "      <td>[after, seeing, film, i, feel, like, i, know, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>My son was 7 years old when he saw this movie,...</td>\n",
       "      <td>[my, son, 7, years, old, saw, movie, russian, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Remember the early days of Pay Per View? I do,...</td>\n",
       "      <td>[remember, early, days, pay, per, view, i, alm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...</td>\n",
       "      <td>1</td>\n",
       "      <td>And that's how the greatest comedy of TV start...</td>\n",
       "      <td>[and, 's, greatest, comedy, tv, started, it, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily Mars, a smalltown girl living in Indiana,...</td>\n",
       "      <td>[lily, mars, smalltown, girl, living, indiana,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_names  labels  \\\n",
       "8283   /home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt       1   \n",
       "10937  /home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...       1   \n",
       "9347   /home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt       1   \n",
       "5430   /home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...       1   \n",
       "4072   /home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt       1   \n",
       "\n",
       "                                                 content  \\\n",
       "8283   After seeing this film I feel like I know just...   \n",
       "10937  My son was 7 years old when he saw this movie,...   \n",
       "9347   Remember the early days of Pay Per View? I do,...   \n",
       "5430   And that's how the greatest comedy of TV start...   \n",
       "4072   Lily Mars, a smalltown girl living in Indiana,...   \n",
       "\n",
       "                                              tokenized1  \n",
       "8283   [after, seeing, film, i, feel, like, i, know, ...  \n",
       "10937  [my, son, 7, years, old, saw, movie, russian, ...  \n",
       "9347   [remember, early, days, pay, per, view, i, alm...  \n",
       "5430   [and, 's, greatest, comedy, tv, started, it, 1...  \n",
       "4072   [lily, mars, smalltown, girl, living, indiana,...  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df_tok3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(\"val_df_tok3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(all_train_tokens,open(\"all_tokens3\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df_tok1.csv\")\n",
    "val_df = pd.read_csv(\"val_df_tok1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "all_train_tokens = pickle.load(open(\"all_tokens1\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 46930 ; token looked much\n",
      "Token looked much; token id 46930\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_df['token_idized'] = token2index_dataset(train_df['tokenized1'])\n",
    "val_df['token_idized'] = token2index_dataset(val_df['tokenized1'])\n",
    "# test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "      <th>tokenized1</th>\n",
       "      <th>token_idized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8283</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>After seeing this film I feel like I know just...</td>\n",
       "      <td>[after, seeing, film, i, feel, like, i, know, ...</td>\n",
       "      <td>[398, 253, 6, 2, 164, 11, 2, 60, 52, 154, 3775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>My son was 7 years old when he saw this movie,...</td>\n",
       "      <td>[my, son, 7, years, old, saw, movie, russian, ...</td>\n",
       "      <td>[303, 407, 1292, 86, 83, 140, 5, 1938, 7135, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Remember the early days of Pay Per View? I do,...</td>\n",
       "      <td>[remember, early, days, pay, per, view, i, alm...</td>\n",
       "      <td>[320, 334, 456, 989, 4016, 638, 2, 147, 320, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...</td>\n",
       "      <td>1</td>\n",
       "      <td>And that's how the greatest comedy of TV start...</td>\n",
       "      <td>[and, 's, greatest, comedy, tv, started, it, 1...</td>\n",
       "      <td>[57, 3, 822, 143, 173, 610, 12, 2435, 86, 170,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>/home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Lily Mars, a smalltown girl living in Indiana,...</td>\n",
       "      <td>[lily, mars, smalltown, girl, living, indiana,...</td>\n",
       "      <td>[4258, 6052, 1, 168, 553, 9632, 1448, 160, 127...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_names  labels  \\\n",
       "8283   /home/cvh255/nlp_hw1/aclImdb/train/pos/4793_7.txt       1   \n",
       "10937  /home/cvh255/nlp_hw1/aclImdb/train/pos/11592_1...       1   \n",
       "9347   /home/cvh255/nlp_hw1/aclImdb/train/pos/3243_8.txt       1   \n",
       "5430   /home/cvh255/nlp_hw1/aclImdb/train/pos/10129_7...       1   \n",
       "4072   /home/cvh255/nlp_hw1/aclImdb/train/pos/9873_7.txt       1   \n",
       "\n",
       "                                                 content  \\\n",
       "8283   After seeing this film I feel like I know just...   \n",
       "10937  My son was 7 years old when he saw this movie,...   \n",
       "9347   Remember the early days of Pay Per View? I do,...   \n",
       "5430   And that's how the greatest comedy of TV start...   \n",
       "4072   Lily Mars, a smalltown girl living in Indiana,...   \n",
       "\n",
       "                                              tokenized1  \\\n",
       "8283   [after, seeing, film, i, feel, like, i, know, ...   \n",
       "10937  [my, son, 7, years, old, saw, movie, russian, ...   \n",
       "9347   [remember, early, days, pay, per, view, i, alm...   \n",
       "5430   [and, 's, greatest, comedy, tv, started, it, 1...   \n",
       "4072   [lily, mars, smalltown, girl, living, indiana,...   \n",
       "\n",
       "                                            token_idized  \n",
       "8283   [398, 253, 6, 2, 164, 11, 2, 60, 52, 154, 3775...  \n",
       "10937  [303, 407, 1292, 86, 83, 140, 5, 1938, 7135, 2...  \n",
       "9347   [320, 334, 456, 989, 4016, 638, 2, 147, 320, 5...  \n",
       "5430   [57, 3, 822, 143, 173, 610, 12, 2435, 86, 170,...  \n",
       "4072   [4258, 6052, 1, 168, 553, 9632, 1448, 160, 127...  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.iloc[2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data_frame = csv_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx,self.data_frame[\"token_idized\"][idx])\n",
    "        token_idx = self.data_frame.iloc[idx][\"token_idized\"]\n",
    "        label = self.data_frame.iloc[idx]['labels']\n",
    "#         print(token_idx)\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_fun(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "#     print(batch[0])\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    for datum in batch:\n",
    "        if datum[1]>MAX_SENTENCE_LENGTH:\n",
    "            padded_vec = np.array(datum[0][:MAX_SENTENCE_LENGTH])\n",
    "        else:\n",
    "            padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH - datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "#         print(padded_vec.shape)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(length_list)), torch.from_numpy(np.array(label_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "train_dataset = IMDBDataset(train_df)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun,\n",
    "                                           shuffle = True)\n",
    "\n",
    "val_dataset = IMDBDataset(val_df)\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_dataset, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun,\n",
    "                                           shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# d = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super(BagOfWords, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx = 0)\n",
    "#         self.linear = nn.Linear(emb_dim,20)\n",
    "        self.linear = nn.Linear(emb_dim,2)\n",
    "#         self.linear2 = nn.Linear(100,300)\n",
    "#         self.linear3 = nn.Linear(300,2)\n",
    "#         self.dp = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "#         out = F.relu(self.linear(out.float()))\n",
    "#         out = F.relu(self.linear2(out.float()))\n",
    "#         out = self.linear3(out.float())\n",
    "#         print(out.size())\n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = [train_loader,val_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,criterion, optimizer, name, num_epochs):\n",
    "    best_loss = np.inf\n",
    "    best_acc = 0\n",
    "    loss_hist = {'train':[],'validate':[]}\n",
    "    for i in range(num_epochs):\n",
    "        for enu,phase in enumerate(['train', 'validate']):\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "            for (data, lengths, labels) in dataloaders[enu]:\n",
    "                data_batch, length_batch, label_batch = data.cuda(), lengths.cuda(), labels.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data_batch, length_batch)\n",
    "                loss = criterion(outputs, label_batch)\n",
    "                if phase=='train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                N = labels.size(0)\n",
    "                \n",
    "                outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "                predicted = outputs.max(1, keepdim=True)[1]\n",
    "#                 print(type(predicted))\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels.view_as(predicted).cuda()).sum().item()\n",
    "                running_loss += loss.data[0] * N\n",
    "                running_total += N\n",
    "            epoch_loss = running_loss/running_total\n",
    "            loss_hist[phase].append(epoch_loss.item())\n",
    "            accuracy = 100 * correct / total\n",
    "            print('Epoch: {}, Phase: {}, epoch loss: {:.4f}, accuracy: {:.4f}'\\\n",
    "                      .format(i,phase,epoch_loss, accuracy))\n",
    "        if phase == 'validate' and epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_acc = accuracy\n",
    "            torch.save(model,name)\n",
    "    print('Best val dice loss: {:4f}, Best Accuracy: {:4f}'.format(best_loss,best_acc))\n",
    "    return model, loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Phase: train, epoch loss: 0.3803, accuracy: 85.3800\n",
      "Epoch: 0, Phase: validate, epoch loss: 0.2652, accuracy: 89.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BagOfWords. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Phase: train, epoch loss: 0.0914, accuracy: 97.8800\n",
      "Epoch: 1, Phase: validate, epoch loss: 0.3003, accuracy: 88.9200\n",
      "Epoch: 2, Phase: train, epoch loss: 0.0213, accuracy: 99.7650\n",
      "Epoch: 2, Phase: validate, epoch loss: 0.3322, accuracy: 89.6200\n",
      "Epoch: 3, Phase: train, epoch loss: 0.0071, accuracy: 99.9800\n",
      "Epoch: 3, Phase: validate, epoch loss: 0.3629, accuracy: 89.6000\n",
      "Epoch: 4, Phase: train, epoch loss: 0.0034, accuracy: 100.0000\n",
      "Epoch: 4, Phase: validate, epoch loss: 0.3902, accuracy: 89.6600\n",
      "Epoch: 5, Phase: train, epoch loss: 0.0020, accuracy: 100.0000\n",
      "Epoch: 5, Phase: validate, epoch loss: 0.4119, accuracy: 89.6400\n",
      "Epoch: 6, Phase: train, epoch loss: 0.0013, accuracy: 100.0000\n",
      "Epoch: 6, Phase: validate, epoch loss: 0.4296, accuracy: 89.5200\n",
      "Epoch: 7, Phase: train, epoch loss: 0.0009, accuracy: 100.0000\n",
      "Epoch: 7, Phase: validate, epoch loss: 0.4468, accuracy: 89.5800\n",
      "Epoch: 8, Phase: train, epoch loss: 0.0007, accuracy: 100.0000\n",
      "Epoch: 8, Phase: validate, epoch loss: 0.4610, accuracy: 89.5800\n",
      "Epoch: 9, Phase: train, epoch loss: 0.0005, accuracy: 100.0000\n",
      "Epoch: 9, Phase: validate, epoch loss: 0.4738, accuracy: 89.6000\n",
      "Best val dice loss: 0.265221, Best Accuracy: 89.640000\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 300\n",
    "model = BagOfWords(len(id2token), emb_dim).cuda()\n",
    "# model = nn.DataParallel(model)\n",
    "learning_rate = 0.01\n",
    "# num_epochs = 100\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "# optimizer = torch.optim.SGD(model)\n",
    "\n",
    "\n",
    "m_save, loss_hists = training(model,criterion,optimizer,\"model15_tokenize2\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_acc = [85.38,97.88,99.76,99.98,100,100,100,100,100,100]\n",
    "val_acc = [89.64,88.92,89.62,89.6,89.66,89.64,89.52,89.58,89.58,89.6]\n",
    "plt.plot(train_acc,label=\"train acc\")\n",
    "plt.plot(val_acc,label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b15673a0dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_hists['train'],label=\"train loss\")\n",
    "plt.plot(loss_hists['validate'],label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(loss_hists,open(\"loss_hist15_t2\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
