{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "MAX_SENTENCE_LENGTH = 400\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"i\",\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"to\",\"from\",\"up\",\"down\",\"in\",\"on\",\"off\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"other\",\"some\",\"such\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "tokenize = spacy.load('en_core_web_sm')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = \"/home/cvh255/nlp_hw1/aclImdb/test/pos/\"\n",
    "test_neg = \"/home/cvh255/nlp_hw1/aclImdb/test/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_files = os.listdir(test_pos)\n",
    "for f in range(len(test_pos_files)):\n",
    "    test_pos_files[f] = test_pos + test_pos_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_files = os.listdir(test_neg)\n",
    "for f in range(len(test_neg_files)):\n",
    "    test_neg_files[f] = test_neg + test_neg_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_labels = [1]*len(test_pos_files)\n",
    "test_neg_labels = [0]*len(test_neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"file_names\",\"labels\"])\n",
    "df[\"file_names\"] = test_pos_files + test_neg_files\n",
    "df[\"labels\"] = test_pos_labels + test_neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    all_txt = []\n",
    "    for i,j in df.iterrows():\n",
    "        f = open(j[\"file_names\"])\n",
    "        txt = f.read()\n",
    "        all_txt.append(txt)\n",
    "    df[\"content\"] = all_txt\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "def tokenize1(phrase):\n",
    "    tokens = tokenize(phrase)\n",
    "    return [token.text.lower() for token in tokens if (token.text not in punctuations and token.text not in stop_words)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset1(dataset,n_gram):\n",
    "    token_dataset = []\n",
    "    all_tokens = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenize1(sample)\n",
    "        bg = list(nltk.bigrams(tokens))\n",
    "        tg = list(nltk.trigrams(tokens))\n",
    "        fg = list(ngrams(tokens,4))\n",
    "        bg_t = [' '.join(a) for a in bg]\n",
    "        tg_t = [' '.join(a) for a in tg]\n",
    "        fg_t = [' '.join(a) for a in fg]\n",
    "        tokens = tokens + bg_t + tg_t + fg_t\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens+=tokens\n",
    "    return token_dataset, all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"tokenized1\"],_ = tokenize_dataset1(test_df['content'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "all_train_tokens = pickle.load(open(\"all_tokens5\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 100000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 50494 ; token i 'm sad\n",
      "Token i 'm sad; token id 50494\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "test_df['token_idized'] = token2index_dataset(test_df['tokenized1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "test_dataset = IMDBDataset(test_df)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super(BagOfWords, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx = 0)\n",
    "        self.linear = nn.Linear(emb_dim,2)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "        out = self.linear(out.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset_test(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data_frame = csv_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.data_frame.iloc[idx][\"file_names\"]\n",
    "        token_idx = self.data_frame.iloc[idx][\"token_idized\"]\n",
    "        label = self.data_frame.iloc[idx]['labels']\n",
    "        return [token_idx, len(token_idx), label,file_name]\n",
    "\n",
    "\n",
    "def pad_fun_test(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    file_names = []\n",
    "    for datum in batch:\n",
    "        \n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "        file_names.append(datum[3])\n",
    "    for datum in batch:\n",
    "        if datum[1]>MAX_SENTENCE_LENGTH:\n",
    "            padded_vec = np.array(datum[0][:MAX_SENTENCE_LENGTH])\n",
    "        else:\n",
    "            padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH - datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(length_list)), torch.from_numpy(np.array(label_list)),np.array(file_names)]\n",
    "\n",
    "test_dataset_test = IMDBDataset_test(test_df)\n",
    "test_loader_test = torch.utils.data.DataLoader(dataset = test_dataset_test, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun_test,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_saved = torch.load(\"model23_tokenize2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "running_loss = 0\n",
    "running_total = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "mod_saved.train(False)\n",
    "\n",
    "for (data, lengths, labels, file_n) in test_loader_test:\n",
    "    data_batch, length_batch, label_batch = data.cuda(), lengths.cuda(), labels.cuda()\n",
    "    outputs = mod_saved(data_batch, length_batch)\n",
    "    outputs = F.softmax(mod_saved(data_batch, length_batch), dim=1)\n",
    "    loss = criterion(outputs, label_batch)\n",
    "    predicted = outputs.max(1, keepdim=True)[1]\n",
    "    mask =(predicted.squeeze(1).eq(label_batch)).cpu().data.numpy()==0\n",
    "    fns = file_n[mask]\n",
    "    tns = file_n[np.array(mask)==False]\n",
    "    actual_out = labels.data.numpy()[mask]\n",
    "    actual_true_out = labels.data.numpy()[np.array(mask)==False]\n",
    "    pred_false = predicted.cpu().data.numpy()[mask]\n",
    "    pred_true = predicted.cpu().data.numpy()[np.array(mask)==False]\n",
    "    running_loss += loss.data[0] * labels.size(0)\n",
    "    running_total += labels.size(0)\n",
    "\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels.view_as(predicted).cuda()).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "epoch_loss = running_loss/running_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is =  89.2 %\n",
      "Cross Entropy loss on test set is =  0.43386340141296387\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test set is = \",accuracy,\"%\")\n",
    "print(\"Cross Entropy loss on test set is = \",epoch_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results :\n",
    "## Accuracy on test set is =  89.2 %\n",
    "## Cross Entropy loss on test set is =  0.43386340141296387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorrect Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/pos/2615_10.txt\n",
      "Charmed was awesome!!!! I don't get how Pheobe goes to the underworld and makes a deal with the source but then in season 4 is back... how does she get back. is there a deleted episode that was never showed?????? i am confused i brought 1 2 3 4 5 and season 8 but am still confused will someone help me help help help h e l p<br /><br />h e l p<br /><br />h e l p <br /><br />h e l p me me me me lull lull Lilllie loll<br /><br />loll loll lull loll Lilla Lilla loll lull<br /><br />Lilllie<br /><br />Lilla loll Lilla Lilla lull loll lull Lilllie Lilllie ll Lilllie lull\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/neg/9200_3.txt\n",
      "I really enjoyed the film. It was really cheesy at times. (They destroy the villain with hair driers--but where are they plugged in?) It's a unique film though, and I enjoyed the acting of Courtney Draper and Tamara Hope. I also enjoyed Fanuel (however you write it...) liking Megan's charecter because she called him a dweeb. Besides the acting, the \"rewinding\" and showing what happened on Ariel's and then Megan's point of view was quite interesting. I saw it twice and I'd see it again\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/pos/9020_10.txt\n",
      "I saw this film a week ago and I had to persuade my friend to come with me because this film seems to be getting such bad reviews. Sure it is no 'Human Traffic' or 'Lock, Stock...' but is by no means a flop. I think the fact that there are so many big budget films out at the moment means it has been ignored but it shouldn't be. I reckon it sets out to do what it wants to do- entertain us for an hour and a half and leave us feeling happy and contented. I would much rather go and see it that 'The Mummy', which looks boring. And no, I'm not a teenager. Don't listen to the critics, Star Wars fans didn't. This film is well worth seeing, if just to see the gorgeous Luke de Lacey and Rupert Penry-Jones. Go see it!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/pos/11314_8.txt\n",
      "Before seeing this picture I was quite skeptic, I don't like movies with an agenda nor do I appreciate being scared into thinking like the writer. I was also afraid this would be like the 2-part mini-series \"10.4\" which had a far-fetched concept, little relation to the real world and very poor execution. At the beginning is says: \"This film is fiction, but the events portrayed and the information about UK emergency planning are based on extensive research\"; and the general feeling is that you're not being sold on an idea, but that you're being taught a lesson in civil awareness. The message that is being conveyed is obvious from the start: It is coming and we're not prepared. The use of real places and a scenario which not only could happen - There are plans for when it does - all add to the disturbing effect the movie will have, on even the most cynical of viewers. The movie's perspective is that of the society and it stays away from heart-breaking personal moments, which won't convey the message, so none of the Romeo-Juliet drama we're used to.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/neg/1560_4.txt\n",
      "OK, so it's a silly movie, but I think they knew that when they made it. And there are some neat little twists on the otherwise tired, overdone \"Godzilla\"-type genre. Borrowed a tape just because I knew someone in it, but I did loan it out to a couple pals, who also kinda liked it.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fns)):\n",
    "    print(\"predicted\",pred_false[i][0])\n",
    "    print(\"Actual\",actual_out[i])\n",
    "    print(test_df[test_df['file_names'] ==fns[i]][\"file_names\"].values[0])\n",
    "    f = open(test_df[test_df['file_names'] ==fns[i]][\"file_names\"].values[0])\n",
    "    print(f.read())\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/neg/10930_1.txt\n",
      "This film is by far the worst film I have ever seen in my life. A woman \"The EX\" pretends to be a number of people in order to gain access to her ex-husband. Killing people for no- reason in baths to achieve her goal. The women I don't think ever went to acting college. She just spends the whole film making stupid expressions, and she looks like she is trying her absolute hardest to avoid looking into the camera. Failing on most occasions. She makes friends with her Ex Husband's wife and son, she does this to use them against her husband. At first when you watch this film, you think that the \"Ex\" wants to kill her ex-husband, maybe because he has treated her in a bad way. But in fact the women is obsessed with the man and wants him back. The two of them used to enjoy rough entertainment (using whips of course). My advice to the general public is do not buy this film, do not rent this film and do not watch it like I did (at 1.15am on FOX)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/pos/6409_10.txt\n",
      "This film is like a dirge. UNTIL it gets to musical numbers which are like MIND F*CK, but gentler, like a mind caress. MIND FOREPLAY. The depressing vibe given from the speed & desperateness of the characters can be pretty Kill-Yourself-Awesome UNTIL you get to the musical numbers. It's a great film. Optimistic. Weird. Manic-depressive(Bipolar). That's it! THIS MOVIE IS BIPOLAR. anyway see it. IT'S A MUSICAL!!! WITH DEPTH!!!! If you like the existential dross like The Stranger, or Waiting for Godot, Then your probably get a real kick out of this one. I had to get the DVD through Amazon.com for like 12$. OH & the songs rock. well they rock but they aren't rock, there like calypso, jazz, Broadway, but by Grace Chung, & I can't find the soundtrack NOWHERE< but i wanna the songs are great, & the dances are so fun.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/pos/5584_8.txt\n",
      "I saw this movie as a child and i am longing to see it again. has it survived? I discount the 1980 version entirely as being fluff. I am sure that there are many that don't feel it is necessary to preserve these films. It is so unfortunate to discover a lost gem after it is gone. Young people today don't realize the hallucinatory quality and the impact on one's life a film seen in early youth can have in later life. This film, \"the blue lagoon\" had that effect on me. How many of us have wished to find ourselves in a place removed of the fears and chaos of the modern world. This was an idyllic story of a boy and girl castaway on a tropical island. there are troubles to be sure but in the end they fall in love and the have a baby. Life should be so simple and beautiful.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/pos/8418_9.txt\n",
      "I am a Maharashtrian, a teenager living in the 21st century, and its obvious that I'm not much into even Bollywood, let alone Marathi movies. Yet, when I watched Shwaas, it left me with a unique feeling, one which only an extremely effective movie is capable of generating.<br /><br />It is a fact that, like most Indian movies, the movie has its true and complete effect only if viewed in its original language. A lot of the emotion and meaning of the movie is embedded in its Marathi dialogues, which, however hard one tries, can not be effectively translated into English.<br /><br />Shwaas explores, in intricate detail, the relationship between a grandparent and a child. And it does complete justice to this strong bond. Dialogues like \"mazha parsha pan laakhat ek aahe\"(My parsha is also one in a million) enhance the emotion. Anyone who has closely observed the grandparent - child relationship will be able to relate to the situation portrayed in the movie.<br /><br />Overall, it definitely worth watching. Its a movie that has left a profound effect on me. I will surely recommend it to anyone!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/test/pos/3124_10.txt\n",
      "This film has to be as near to perfect a film as John Ford made. The film is magic, a masterpiece, the reason Ford was, well Ford. If you want to know why Ford was great this one explains it.<br /><br />The photography of course is superb, black and white as black and white should be, wonderful shots, not an over the shoulder conversation in it, pure Ford, great moments, big and little. The famous ripped pants of Ward Bond. Apparently two dogs kept invading the set and fighting so Ford wanted to use them in the fighting scene, but instead of fighting one dog ran away and the other attacked Ward Bond and ripped his pants, which caused Ford no end of mirth. A whole scene around plaiting a rope. The way Ben Johnson burn then snuffs his rope, wonderful foreshadowing and anticipation of the final. Harry Carey's naive courting of Prudence. The usual ford line about being scared and not showing it. Bond's horse accidentally falling in him and its left in the film. Johnson and Bond are fantastic in that scene. Lord help any Ford actor who does not stay in character while the camera is rolling even when a horse falls on top of you.<br /><br />A couple of very sweet romances, not intruding on the whole focus, two very likable leads, not to mention for the girls, the number of times the cameras focus on Ben Johnson's rather delightful backside.<br /><br />Lots of old time stuntmen getting lines and roles, Cliff Lyons, Frank McGrath. Some wonderful character studies mostly of faces staring, all the villains and main stars. A set of villains to rival any group in any western.<br /><br />Many many Fordian shots of faces, groups, children, women, small things happening, foals in the background (Ford seems to love images of foals), women in aprons, allowing the moment as wagons cross rivers and the camera lingers.<br /><br />This is probably not a western as much as an artist's picture that happens to be set in the west.<br /><br />Lucky the film was made in 1950 because it is impossible to imagine such a film could be ever made again, but then it is such a work of art that it would be a sacrilege to attempt it\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tns)-5,len(tns)):\n",
    "    print(\"predicted\",pred_true[i][0])\n",
    "    print(\"Actual\",actual_true_out[i])\n",
    "    print(test_df[test_df['file_names'] == tns[i]][\"file_names\"].values[0])\n",
    "    f = open(test_df[test_df['file_names'] == tns[i]][\"file_names\"].values[0])\n",
    "    print(f.read())\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorrect Predictions on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"val_df_tok5.csv\")\n",
    "val_df['token_idized'] = token2index_dataset(val_df['tokenized1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_test = IMDBDataset_test(val_df)\n",
    "val_loader_test = torch.utils.data.DataLoader(dataset = val_dataset_test, \n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           collate_fn = pad_fun_test,\n",
    "                                           shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, lengths, labels, file_n = next(iter(val_loader_test))\n",
    "data_batch, length_batch, label_batch = data.cuda(), lengths.cuda(), labels.cuda()\n",
    "outputs = mod_saved(data_batch, length_batch)\n",
    "outputs = F.softmax(mod_saved(data_batch, length_batch), dim=1)\n",
    "predicted = outputs.max(1, keepdim=True)[1]\n",
    "mask =(predicted.squeeze(1).eq(label_batch)).cpu().data.numpy()==0\n",
    "fns = file_n[mask]\n",
    "actual_out = labels.data.numpy()[mask]\n",
    "pred_false = predicted.cpu().data.numpy()[mask]\n",
    "tns = file_n[np.array(mask)==False]\n",
    "actual_true_out = labels.data.numpy()[np.array(mask)==False]\n",
    "pred_true = predicted.cpu().data.numpy()[np.array(mask)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/pos/7671_10.txt\n",
      "Dr. Mordrid, what can I say? Jeffrey Combs has done it again!<br /><br />Anton Mordrid has been on Earth for 100 years waiting for Kabal, an evil sorcerer, to come so he can kill him. Mordrid and Kabal used to train together as kids, so Mordrid knows all Kabal's tricks.<br /><br />The film as a little bit confusing at begin with, but soon you feel a part of the action. I won't give away the ending, so go and watch Doctor Mordrid!<br /><br />I found the film to be very enjoyable because it doesn't have a lot of violence in, nor sexual scenes. The film focused on the plot and that's what I like! I find the best films are the ones where times seems to fly by. This is because you are so engrossed in the film. Doctor Mordrid is a fantasticly engrossing movie! I give it a 20 out of 10. Worth seeing!<br /><br />\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/pos/12213_10.txt\n",
      "A great and truly independent film that hit most of my emotions and carried me into another world. Isn't this why we go to the movies? I was especially impressed with the editing and the music, the combination of which was very transportive.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/pos/3875_9.txt\n",
      "This movie has been made by one of the most absurd humorists in Canada, Yves P. Pelletier. I was shocked for a second that he made a ROMANTIC comedy, but knowing he was a heavy cinephile, was seen in every local festival and in the local cinematheque, I had a positive feeling about this movie.<br /><br />Hell, I was right. Right off the bat, the scenario (written by Pelletier himself) is a bit twisted and hard to follow, but, in Pelletier's fashion it's a one-of-a-kind 90 minutes jack-in-the-box.<br /><br />Loosely inspired and mostly transformed allusion to Dangerous Liaisons (by Laclos) \"Les Aimants\" consists of a twisted game of writing notes on the fridge. Throughout the movie you'll get the occasion to find out who's who and who's writing to who on that goddam fridge....which pops up in an interesting love affair.<br /><br />Great storyline, great photography, great quotations of other movies. Should we ask more for a first movie?\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/pos/2696_8.txt\n",
      "Police, investigations, murder, suspicion: we are all so acquainted with them in movies galore. Most of the films nowadays deal with crime which is believed to involve viewers, to provide them with a thrilling atmosphere. However, most of thrill lovers will rather concentrate on latest movies of that sort forgetting about older ones. Yet, it occurs that these people may easily be misled. A film entirely based on suspicion may be very interesting now despite being more than 20 years old...it is GARDE A VUE, a unique movie by Claude Miller.<br /><br />Is there much of the action? Not really since the events presented in the movie take place in a considerably short time. But the way they are executed is the movie's great plus. Jerome Charles Martinaud (Michel Serrault) is being investigated by Inspector Gallien (Lino Ventura) and Insector Belmont (Guy Marchand). It's a New Year's Eve, a rainy evening and not very accurate for such a meeting. Yet, after the rape and murder of two children, at the dawn of the old year, the door of suspicion must be open at last. In other words, (more quoted from the movie), it must be revealed who an evil wolf really is. To achieve this, one needs lots of effort and also lots of emotions from both parties...<br /><br />Some people criticize the script for being too wordy. Yet, I would ask them: what should an investigation be like if not many questions and, practically, much talk. This wordiness touches the very roots of the genre. In no way is this boring but throughout the entire film, it makes you, as a viewer, as an observer, involved. Moreover, the film contains well made flashbacks as the stories are being told. Not too much and not too little of them - just enough to make the whole story clearer and more interesting. The most memorable flashbacks, for me, are when Chantal (Romy Schneider), Martinaud's wife, talks about one lovely Christmas... But these flashbacks also contain the views of the places, including the infamous beach. It all wonderfully helped me keep the right pace. And since I saw GARDE A VUE, I always mention this film as one of the \"defenders\" of French cinema against accusations of mess and chaos. <br /><br />But those already mentioned aspects may not necessarily appeal to many viewers since they might not like such movies and still won't find the content and its execution satisfactory. Yet, GARDE A VUE is worth seeing also for such people. Why? For the sake of performances. But here don't expect me to praise foremost Romy Schneider. GARDE A VUE is not Romy Schneider vehicle. She does a terrific job as a mother who is deeply in despair for a lost child. She credibly portrays a person who is calm, concrete, who does not refuse an offered cup of tea but who does not want to play with words. Her part which includes a profound talk of life and duty is brilliant, more credible than the overly melancholic role of Elsa in LA PASSANTE DE SANS SOUCI. It is still acted. However, Romy Schneider does not have much time on screen. Practically, she appears for the first time after 45 minutes from the credits; she, as a wife and a different viewpoint, comes symbolically with the New Year, at midnight. Her role is a purely supporting one. Who really rocks is Lino Ventura. He IS the middle aged Inspector Antoine Gallien who wants to find out the truth, who is aware that his questions are \"missiles\" towards the other interlocutor but does not hesitate. He is an inspector who, having been married three times, is perfectly acknowledged of women's psyche. He is the one who does not regard his job as a game to play but a real service. Finally, he is a person who does not find it abnormal to sit there on New Year's Eve. Michel Serrault also does a fine job expressing fear, particularly in the final scenes of the movie. But thumbs up for Mr Ventura. Brilliant!<br /><br />As far as memorable moments are concerned, this is not the sort of film in which this aspect is easily analyzed. The entire film is memorable, has to be seen more than once and has to be felt with its atmosphere and, which I have not mentioned before, gorgeous music. For me, the talk of Chantal and Inspector Gallien is the most brilliant flawless moment. You are there with the two characters, you experience their states of mind if you go deeper into what you see.<br /><br />GARDE A VUE is a very interesting film, a must see for thrill lovers and connoisseurs of artistic performances. New Year has turned and...is it now easier to open the door? You'll find out when you decide to see the memorably directed movie by Claude Miller. 8/10\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fns)-4,len(fns)):\n",
    "    print(\"predicted\",pred_false[i][0])\n",
    "    print(\"Actual\",actual_out[i])\n",
    "    print(val_df[val_df['file_names'] ==fns[i]][\"file_names\"].values[0])\n",
    "    f = open(val_df[val_df['file_names'] ==fns[i]][\"file_names\"].values[0])\n",
    "    print(f.read())\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Predictions on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/11611_3.txt\n",
      "Lady in Cement - PI spoof with ole Blue Eyes.Frank Sinatra is a shamus on a houseboat in Miami in this rarely funny \"comedy\".Burdened by an annoying and repetitious Hugo Montenegro score and bunch of misfiring punchlines this 1968 flick just never rises above slightly too bawdy to be on TV made for television movie status.Dan Blocker is effective in the Mike Mazurski/Ted De Corsia big galoot role and Raquel Welch should thank her personal trainer.The only thing that makes the DVD worth keeping or seeing is the collection of cheesy trailers for Welch flicks like Bandolero,Fantastic Voyage , Mother ,Jugs & Speed and Myra Breckinridge.Even if you get the DVD-skip the predictable movie and go for the trailer library in the special features.Besides tons of mysoginistic asides-Sinatra lisps @ the homosexual owners of the local Go-Go bar.A relic that needs to be put back in the time capsule. D\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/7141_3.txt\n",
      "Okay so I went into this movie not really expecting much I figured an action flick similar to The Fast and the Furious. Some nice cars some nice girls somewhat of a decent plot. Unfortunately I would have to say that this was probably the worst movie I have seen this year. Don't get me wrong the cars were nice and the girls were OK but the way they put the movie together was just plain crappy to put it nicely. The story just never made you care about the cast and the movie seemed just pieced together. So overall this movie was not the worst thing ever by far but if your looking for a movie to go to this weekend I would pass on this one for now.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/7337_1.txt\n",
      "Painful. Painful is the only word to describe this awful rendition of such a fun and interesting Shakespearean play. I gave it a shot but was terribly disappointed and couldn't bare to even finish viewing it. To the person who wrote a novel about how wonderful this twist of Much Ado was, I pity you and your bored brain. May your pretenses about young viewers be lifted without retribution. Please do not even bother with this gut wrenching, disgusting excuse for a performance of an acclaimed Shakespeare drama. You will be forced to induce vomiting and will require a commode close to the television with which you choose to watch this crap because involuntary defecation will take place.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 0\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/neg/9814_1.txt\n",
      "This is the kind of movie you regret you put in your VCR. It is some weird bad rip off version of Stephen kings movie \"Misery (1990)\". I cannot understand how this movie got a 5.2 score, because it has no story what so ever, and when the movie finally ended, I was relieved.<br /><br />This movie should have been released as a short-movie instead.. to much time is spent on the same thing. And as in every bad movie, everything happens just at the end of the movie in a 10-15 minutes time span...<br /><br />So, before you decide to watch this movie, be sure to put some new batteries in your remote control, because you are going to do whole lot of fast-forwarding... don't worry, you wont miss anything important.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 1\n",
      "/home/cvh255/nlp_hw1/aclImdb/train/pos/3598_10.txt\n",
      "Being a person who does not usually enjoy boxing movies, feeling they only focus on the boxing and not the characters themselves, this movie truly moved me. I loved being able to see the main character Diana(Michelle Rodriguez) go through so many things in such a short while, it was amazing to me. Michelle (Rodriguez) did such a wonderful job playing Diana especially since this was her first acting experience, she showed true emotion and portrayed Diana wonderfully. All actors had chemistry on screen and made this movie even more amazing. I highly recommend this movie even to those who do not usually watch boxing movies. 10/10\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tns)-5,len(tns)):\n",
    "    print(\"predicted\",pred_true[i][0])\n",
    "    print(\"Actual\",actual_true_out[i])\n",
    "    print(val_df[val_df['file_names'] == tns[i]][\"file_names\"].values[0])\n",
    "    f = open(val_df[val_df['file_names'] == tns[i]][\"file_names\"].values[0])\n",
    "    print(f.read())\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
